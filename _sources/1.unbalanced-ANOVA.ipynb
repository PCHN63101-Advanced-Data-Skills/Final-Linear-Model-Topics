{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6b3fd6-1753-45e7-a920-fccf68cbdcac",
   "metadata": {},
   "source": [
    "# Unbalanced ANOVA Models\n",
    "\n",
    "```{figure} images/unbalanced-text.webp\n",
    "---\n",
    "scale: 80%\n",
    "align: right\n",
    "---\n",
    "```\n",
    "\n",
    "... Indeed, whole textbooks were written about unbalanced data (as can be seen on the *right*). So this is a topic that deserves some attention, even if it is largely *ignored* by modern teaching in Psychology. There is something of an assumption that the issues of balance have been *solved* and thus do not need considering anymore. However, this is not really true. The \"solution\" implemented by SAS and SPSS is the Type III sums-of-squares, which researchers continue to use because it is the default[^default-foot]. However, as discussed briefly last week, this approach is highly flawed.\n",
    "\n",
    "In this part of the lesson, we will dig deeper into the Type I/II/III debate so that you understand what each type of sums-of-squares means, when they are most appropriate to use and what the various arguments are for/against them. In general, we will be recommending Type II for 95% of all use-cases. However, it is important not to just take our word for it. Instead, it is important that you *understand* the difference and can make your own informed judgement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0431a6c5",
   "metadata": {},
   "source": [
    "## The Problem of Imbalance\n",
    "The arithmetic behind the traditional ANOVA relates to a simple decomposition of the sums-of-squares. When there are an equal number of data points in each cell (using a 2-way ANOVA as an example), we simply have\n",
    "\n",
    "$$\n",
    "SS_{\\text{A}} + SS_{\\text{B}} + SS_{\\text{AB}} = SS_{\\text{Model}}.\n",
    "$$\n",
    "\n",
    "So, the total amount of variance explained by the model can be neatly decomposed into several chunks. These decompositions are said to be *orthogonal*, which you can take to mean *independant*. The value of each sum-of-squares is not affected by any of the others and they represent a neat and simple partition of the amount explained by the model. Together, we then have\n",
    "\n",
    "$$\n",
    "SS_{\\text{Total}} = SS_{\\text{Model}} + SS_{\\text{Error}}.\n",
    "$$\n",
    "\n",
    "Unfortunately, when there is an *unequal* number of data points across cells, application of the standard ANOVA equations results in\n",
    "\n",
    "$$\n",
    "SS_{\\text{A}} + SS_{\\text{B}} + SS_{\\text{AB}} > SS_{\\text{Model}}.\n",
    "$$\n",
    "\n",
    "Adding these decompositions together is now *not* the same as the amount of variance explained by the model. What happens is that the effects \"bleed\" into each other. They no longer represent an independent partition of the variance. A lack of balance kills the symmetry that allows the ANOVA to neatly decompose the variance. What this means practically is that each effect now contains some element of the other effects and adding them together means we double-count some chunks of variance. This leads to a larger sum $\\left(SS_{\\text{A}} + SS_{\\text{B}} + SS_{\\text{AB}}\\right)$ than the model actually explains. \n",
    "\n",
    "What does this mean in terms of applying an ANOVA model to unbalanced data? It means that each sums-of-squares we calculate is influenced *by the other terms in the model*. This means we have several options when we decompose the sums-of-squares related to what else is in the model at the time. Each chunk that gets calculated will represent the variance associated with a given effect *minus* the overlap with anything else in the model. Unfortunately, wherever there is choice, there is also disagreement. For an unbalance ANOVA, this disagreement surrounds three possible ways of decomposing the sums-of-squares in an unbalanced ANOVA model. These are known as Type I, Type II and Type III sums-of-squares and will be the focus of this part of the lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e15f1ab",
   "metadata": {},
   "source": [
    "### Venn Diagram Intuition\n",
    "Perhaps the simplest way to gain intuition about what happens in an unbalanced ANOVA is to return to the Venn diagram visualisation we saw previously in multiple regression. Here, each circle represents the sum-of-squares associated with each main effect $\\text{A}$ and $\\text{B}$, along with their interaction $\\text{AB}$.\n",
    "\n",
    "When the ANOVA is *balanced*, the situation is as shown below\n",
    "\n",
    "```{figure} images/venn-diagrams/orthog-ANOVA.png\n",
    "---\n",
    "scale: 55%\n",
    "align: center\n",
    "---\n",
    "```\n",
    "\n",
    "Here, there is no overlap between the circles. Each effect is completely independant and it does not mater what else is in the model at the point where we calculate its sum-of-squares. We could entirely remove $\\text{B}$ and $\\text{AB}$ when calculating $SS_{\\text{A}}$ and it would not make any difference. The other model terms therefore do not matter[^modterms-foot].\n",
    "\n",
    "When the ANOVA is *unbalanced*, the situation is as shown below\n",
    "\n",
    "```{figure} images/venn-diagrams/unbalanced-ANOVA.png\n",
    "---\n",
    "scale: 55%\n",
    "align: center\n",
    "---\n",
    "```\n",
    "\n",
    "Here, the effects now *overlap*. This means there is some element of both $\\text{B}$ and $\\text{AB}$ inside the sum-of-squares for $\\text{A}$. This tells us why the sum of these terms is too big. If we sum the area of the $\\text{A}$ circle, $\\text{B}$ circle and $\\text{C}$ circle we will double-count the areas of overlap. This will be larger than the total area of all the circles (the $SS_{\\text{Model}}$). Furthermore, because each sum-of-squares will now depend upon the other terms in the model, we now have several options when it comes to calculating them. \n",
    "\n",
    "Using $SS_{\\text{A}}$ as an examples, we could \n",
    "\n",
    "- Calculate $SS_{\\text{A}}$ with nothing else in the model\n",
    "- Calculate $SS_{\\text{A}}$ with $\\text{B}$ in the model, but no $\\text{AB}$. \n",
    "- Calculate $SS_{\\text{A}}$ with *both* $\\text{B}$ and $\\text{AB}$ in the model. \n",
    "\n",
    "In each case, the $SS_{\\text{A}}$ will represent only the *unique* portion of the cicle, with the overlaps removed. These options are illustrated below and correspond to the Type I, Type II and Type III sums-of-squares.\n",
    "\n",
    "```{figure} images/venn-diagrams/SS-Types.png\n",
    "---\n",
    "scale: 55%\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2626aa56",
   "metadata": {},
   "source": [
    "## The Principle of Marginality\n",
    "In trying to determine which of the sums-of-squares to choose, we can be guided by the idea of building *meaningful* models. This is encapsulated by the *principle of marginality*, which was laid out by [Nelder (1977)](https://www.jstor.org/stable/2344517) as a response to his dissatisfaction with the way that linear models were being applied in statistics. In brief, this principle states that *if an interaction is in the model, all the constituent lower-order terms must also be in the model*.\n",
    "\n",
    "For example, if we include $\\text{AB}$, we must also include $\\text{A}$ and $\\text{B}$. If we include $\\text{ABC}$ we must also include $\\text{A}$, $\\text{B}$, $\\text{C}$, $\\text{AB}$, $\\text{AC}$, $\\text{BC}$. From this perspective, interpretation flows *downwards*. We interpret the highest-order significant terms and ignore any lower-order terms that are nested inside it. We must start at the *bottom* of the ANOVA table and work our way up, respecting marginality along the way. This reflects the fact that removing a lower-order term destroys the meaning of the interaction term. Remember, an interaction is defined as a *departure from additivity*. Without the additive components present in the model, this deviation has no meaning. \n",
    "\n",
    "For instance, if we fit the model\n",
    "\n",
    "$$\n",
    "y_{ijk} = \\mu + \\beta_{k} + (\\alpha\\beta)_{jk} + \\epsilon_{ijk},\n",
    "$$\n",
    "\n",
    "then there is no main effect of $\\text{A}$, there is only the main effect of $\\text{B}$ and the $\\text{AB}$ interaction. However, the interaction term $(\\alpha\\beta)_{jk}$ will no longer behave as a \"deviation from additivity\". Instead, it will need to soak-up both the main effect of $\\text{A}$ and the $\\text{AB}$ interaction. So the value of this term will be a combination of the main effect and the interaction, which is uninterpretable. This is all because this model does not respect the principle of marginality and thus the clean interpretation of each term is destroyed. Although the model above does not seem sensible, we will see below that the Type III sums-of-squares actually make *implicit* comparisons with these forms of models.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a741b7",
   "metadata": {},
   "source": [
    "## Type I Sums-of-squares\n",
    "As indicated above, the Type I sums-of-squares for factor $\\text{A}$ are calculated based on nothing else being in the model. However, this does not tell the full story. To understand these effects, it is useful to introduce some new notation. In comparing the following two models\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    \\mathcal{M}_{0} &: y_{ijk} = \\mu + \\beta_{k} + \\epsilon_{ijk} \\\\\n",
    "    \\mathcal{M}_{1} &: y_{ijk} = \\mu + \\alpha_{j} + \\beta_{k} + \\epsilon_{ijk} \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "we can denote the *reduction* in sums-of-squares as follows\n",
    "\n",
    "$$\n",
    "R(\\alpha|\\beta).\n",
    "$$\n",
    "\n",
    "This is read as \"the reduction in residual sums-of-squares for $\\alpha$, after taking $\\beta$ into account\". So the terms on the *left* of $|$ are added and removed between the two models, whereas the terms on the *right* of $|$ remain in both models.\n",
    "\n",
    "With this in mind, the Type I sums-of-squares are a *sequential* decomposition, where terms are added *in the same order* as the model equation. Thus, for a 2-way ANOVA, the sums-of-squares for each term are as follows\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    SS_{\\text{A}}  &: R(\\alpha|\\mu)        \\\\\n",
    "    SS_{\\text{B}}  &: R(\\beta|\\mu, \\alpha) \\\\\n",
    "    SS_{\\text{AB}} &: R((\\alpha\\beta)|\\mu, \\alpha, \\beta)\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "As such, the order of the model equation matters here, as each term is added *in turn* and then compared to the previous model. So we start with only $\\mu$, we then add $\\alpha$ and see what the difference is. We then add $\\beta$ and see what the difference is from the model containing both $\\mu$ and $\\alpha$, and so on.\n",
    "\n",
    "In terms of the Venn diagram intuition, we can see below what the standard order of terms produces in terms of the Type I tests.\n",
    "\n",
    "```{figure} images/venn-diagrams/SS-I.png\n",
    "---\n",
    "scale: 50%\n",
    "align: center\n",
    "---\n",
    "```\n",
    "\n",
    "Of these, the test of $\\text{B}$ and $\\text{AB}$ are useful because they take other terms into account. However, the test of $\\text{A}$ is less useful, because it does not take the effect of $\\text{B}$ into account. Importantly, however, this will change entirely if the model is specified in a *different* order. This reliance on order makes the Type I sums-of-squares dubious in their usefulness. Unfortunately, this is exactly what the `anova()` function from base `R` produces and why this method is not really suitable for *unbalanced* data. Here, the adherence to marginality depends entirely upon the order in which the terms enter the model and will only produce *some* useful tests, but not necessarily all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7683d8",
   "metadata": {},
   "source": [
    "`````{admonition} Why does R default to Type I sums-of-squares?\n",
    ":class: info\n",
    "It may seem strange that the `anova()` function would choose to use the Type I sums-of-squares. However, we need to understand that `anova()` is only designed for use on *balanced* data. With this in mind, the choice of decomposition technique is entirely due to computational ease. The Type I effects are easy to calculate because we simply loop through each term, comparing the change in residual sums-of-squares to the previous model. Under balance, this is identical to the traditional ANOVA decompositon and is also identical to Type II and Type III tests. From this perspective, it is easy to see why `anova()` does things this way. However, it is important to understand that this should not be used with *unbalanced* data. At least, not without understanding what the tests actually mean.\n",
    "``````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d934b6e9",
   "metadata": {},
   "source": [
    "## Type II Sums-of-squares\n",
    "... In terms of their adherence to marginality, the Type II sums-of-squares are the *only* method of the 3 that does respect marginality.\n",
    "\n",
    "```{figure} images/venn-diagrams/SS-II.png\n",
    "---\n",
    "scale: 50%\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51260ac5",
   "metadata": {},
   "source": [
    "## Type III Sums-of-squares\n",
    "... In terms of their adherence to marginality, the Type III sums-of-squares *ignore* marginality. Instead choosing to compare models of the form\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    \\mathcal{M}_{0} &: y_{ijk} = \\mu + \\beta_{k} + (\\alpha\\beta)_{jk} + \\epsilon_{ijk} \\\\\n",
    "    \\mathcal{M}_{1} &: y_{ijk} = \\mu + \\alpha_{j} + \\beta_{k} + (\\alpha\\beta)_{jk} + \\epsilon_{ijk} \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "In other words, by considering a model that contains an interaction, without one of the associated main effects. This is arguably a wholly *meaningless* model, where we simultaneously suggest that there is 0 difference between the levels of a factor, but also that this difference changes depending upon another factor. What this model comparison ends up calculating is the effect of A after removing the effect of B *and* AB. So a main effect with the interaction *removed*. So what exactly does this mean? If we pretend that the effect of A does not depend upon B, what would the effect of A be? If there is a meaningful interaction, this is then calculating a fantasy. To bring back the example from last week, if the effectiveness of a treatment depends upon diagnosis, if makes little sense to calculate the effect of treatment *ignoring* diagnosis. It is like someone asking you whether the treament works, and you ask them what the diagnosis is and they refuse to answer and just ask you again whether the treatment works. From this perspective, Type III sums-of-squares are of little use to us, despite being the default in many statistical packages.\n",
    "\n",
    "```{figure} images/venn-diagrams/SS-III.png\n",
    "---\n",
    "scale: 50%\n",
    "align: center\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5c879e",
   "metadata": {},
   "source": [
    "## When Do the Sums-of-squares *Not* Matter?\n",
    "... Balance, $t$-tests, oneway ANOVA and multiple regression with only continuous predictors..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026f334",
   "metadata": {},
   "source": [
    "## Sums-of-Squares in `R`\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0201f652",
   "metadata": {
    "tags": [
     "hide-input"
    ],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data(mtcars)\n",
    "\n",
    "# Origin factor\n",
    "mtcars$origin <- c('Japan','Japan','USA','USA','USA','USA','USA','Europe','Europe',\n",
    "                   'Europe','Europe','Europe','Europe','Europe','USA','USA','USA',\n",
    "                   'Europe','Japan','Japan','Japan','USA','USA','USA','USA',\n",
    "                   'Europe','Europe','Europe','USA','Europe','Europe','Europe')\n",
    "mtcars$origin <- as.factor(mtcars$origin)\n",
    "\n",
    "# VS factor\n",
    "vs.lab <- rep(\"\",length(mtcars$vs)) \n",
    "vs.lab[mtcars$vs == 0] <- \"V-shaped\"\n",
    "vs.lab[mtcars$vs == 1] <- \"Straight\"\n",
    "mtcars$vs <- as.factor(vs.lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f98362",
   "metadata": {},
   "source": [
    "We can examine the degree of imbalance using the `tables()` function to generate a contingency table of the factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c3627b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        vs\n",
       "origin   Straight V-shaped\n",
       "  Europe        8        6\n",
       "  Japan         3        2\n",
       "  USA           3       10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with(mtcars, table(origin,vs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07c006b7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mpg.mod <- lm(mpg ~ origin + vs + origin:vs, data=mtcars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b3e6c9",
   "metadata": {},
   "source": [
    "### Type I and Type II in `R`\n",
    "Type I and II sums-of-sqaures are simple to produce. For Type I, we simply use the built-in `anova()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c2f0a48",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of Variance Table\n",
      "\n",
      "Response: mpg\n",
      "          Df Sum Sq Mean Sq F value    Pr(>F)    \n",
      "origin     2 393.88 196.938 11.4370 0.0002733 ***\n",
      "vs         1 282.26 282.261 16.3921 0.0004117 ***\n",
      "origin:vs  2   2.21   1.104  0.0641 0.9380730    \n",
      "Residuals 26 447.70  17.219                      \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "print(anova(mpg.mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9090a2ba",
   "metadata": {},
   "source": [
    "Note that whilst we might think we could recreate these through model comparisons, only the sums-of-squares will agree. All these tests use the error term from the model containing *all* the factors. So we can recreate the *numerators* of the $F$-statistics, but the denominators will not be the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e95721",
   "metadata": {},
   "source": [
    "For Type II, we can simply use `Anova()` without any options, as the Type II tests are the default. We can also specify `type='II'`, if we want to be explicit about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f6c2db5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type II tests)\n",
      "\n",
      "Response: mpg\n",
      "          Sum Sq Df F value    Pr(>F)    \n",
      "origin    179.61  2  5.2153 0.0124621 *  \n",
      "vs        282.26  1 16.3921 0.0004117 ***\n",
      "origin:vs   2.21  2  0.0641 0.9380730    \n",
      "Residuals 447.70 26                      \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "print(Anova(mpg.mod)) # or Anova(mpg.mod, type=\"II\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d3c349",
   "metadata": {},
   "source": [
    "As expected, both `origin:vs` and `vs` are the same as the Type I tests, but `origin` is different. Refer back to the Venn diagrams to see why this is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf29d95",
   "metadata": {},
   "source": [
    "\n",
    "### Type III in `R`\n",
    "For Type III, things get trickier. Recall from above that a Type III main effect is making the implicit comparison\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    \\mathcal{M}_{0} &: y_{ijk} = \\mu + \\beta_{k} + (\\alpha\\beta)_{jk} + \\epsilon_{ijk} \\\\\n",
    "    \\mathcal{M}_{1} &: y_{ijk} = \\mu + \\alpha_{j} + \\beta_{k} + (\\alpha\\beta)_{jk} + \\epsilon_{ijk} \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "So you might think we can compare `y ~ A + B + A:B` to `y ~ B + A:B`. Unfortunately, this will not work. ... In fact, not actual model comparison exists that will generate the Type III test for us because the models will not behave in the way the Type III tests require. This in and of itself should indicate why Type III is not doing anything sensible. The approach that `Anova()` uses is based on manipulating the model parameters to create the comparison that the Type III tests imply. However, in order to do this correctly, we need to use a *very specific dummy coding scheme*. ...\n",
    "\n",
    "We have two options here. The first is to change the dummy coding *globally* using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbcb826c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(contrasts=c('contr.sum','contr.poly'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3c3f81",
   "metadata": {},
   "source": [
    "The disadvantage of doing this is that this will change the interpretation of the parameters in all the model you use after setting this, unless you remember to set it back to normal afterwards. This means you always need to specify models in the following way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc216bc",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: carData\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: mpg\n",
      "             Sum Sq Df  F value    Pr(>F)    \n",
      "(Intercept) 10488.5  1 609.1096 < 2.2e-16 ***\n",
      "vs            251.9  1  14.6285 0.0007372 ***\n",
      "origin        166.5  2   4.8354 0.0163901 *  \n",
      "vs:origin       2.2  2   0.0641 0.9380730    \n",
      "Residuals     447.7 26                       \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "library(car)\n",
    "\n",
    "options(contrasts=c('contr.sum','contr.poly'))              # set sum-to-zero coding\n",
    "mod.sum <- lm(mpg ~ vs + origin + vs:origin, data=mtcars)   # fit model\n",
    "print(Anova(mod.sum, type='III'))                           # Type III ANOVA table\n",
    "options(contrasts=c('contr.treatment','contr.poly'))        # puting the coding back to default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ba2ceb",
   "metadata": {},
   "source": [
    "The better approach, though the more messy in terms of syntax, is to tell `lm()` how to code each variable explicitly. This can be done using the `contrasts=` argument, which takes a list of each factor alongside how we want them coded. For this example, we will therefore use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a7be63",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: mpg\n",
      "             Sum Sq Df  F value    Pr(>F)    \n",
      "(Intercept) 10488.5  1 609.1096 < 2.2e-16 ***\n",
      "vs            251.9  1  14.6285 0.0007372 ***\n",
      "origin        166.5  2   4.8354 0.0163901 *  \n",
      "vs:origin       2.2  2   0.0641 0.9380730    \n",
      "Residuals     447.7 26                       \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "mod.sum <- lm(mpg ~ vs + origin + vs:origin, data=mtcars, \n",
    "              contrasts=list(vs=contr.sum, origin=contr.sum)) # fit model w/specific coding\n",
    "print(Anova(mod.sum, type='III'))                             # Type III ANOVA table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc83a34",
   "metadata": {},
   "source": [
    "This additional hassle and the dependence of the Type III tests on something as arbitrary as the model coding should be enough to dissuade you from this approach. Indeed, this very dependence is the reason why `Anova()` will *not* refit the model for you and automatically change the coding. [John Fox](https://uk.sagepub.com/en-gb/eur/author/john-david-fox) (the author of `car`) wants this dependence to be clear. Type I and Type II effects do not change with the dummy variable scheme. Type III effects *do* change. This fact needs to be *understood*, not *hidden*.\n",
    "\n",
    "All that being said, if you want an easier method, there is the `ezANOVA()` function from the `ez` package. This will take care of all the coding mess for you behind the scenes. However, there are some distinct disadvantages here:\n",
    "\n",
    "- `ezANOVA` aims to create output that mimics SPSS. This is not done within the linear models framework, meaning there is not access to residuals, diagnostic plots, parameter estimates or any of the useful output we want. You get an ANOVA table and nothing else[^ez-foot].\n",
    "- By abstracting away the difficulties of Type III tests, `ezANOVA` gives the impression of simplicity and does not engage you with any of the controversy. It prints a generic warning under imbalance, but nothing else.\n",
    "- Fundammentally, this package aims to re-express linear models in the language of Psychology and then *hide* information from you. This is is rarely a good thing. If this is what someone needs in order to use `R`, it is arguable that they should not be using it at all.\n",
    "\n",
    "Nevertheless, if you want the simplest possible method of generating a Type III table, you can do the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a7d7233",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“Data is unbalanced (unequal N per group). Make sure you specified a well-considered value for the type argument to ezANOVA().”\n",
      "Coefficient covariances computed by hccm()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Effect DFn DFd           F            p p<.05         ges\n",
      "2        vs   1  26 14.62853431 0.0007372137     * 0.360055674\n",
      "3    origin   2  26  4.83541867 0.0163900610     * 0.271113270\n",
      "4 vs:origin   2  26  0.06408491 0.9380730371       0.004905426\n"
     ]
    }
   ],
   "source": [
    "library(ez)\n",
    "\n",
    "mtcars$idx <- as.factor(seq(from=1, to=dim(mtcars)[1])) # ezANOVA needs subject IDs\n",
    "ezAOV      <- ezANOVA(data=mtcars,          # data\n",
    "                      dv=mpg,               # outcome\n",
    "                      between=.(vs,origin), # between-subject factors  \n",
    "                      wid=idx,              # subject IDs\n",
    "                      type=3)               # sums-of-squares\n",
    "\n",
    "print(ezAOV$ANOVA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673b548d",
   "metadata": {},
   "source": [
    "## The Sums-of-squares Circus\n",
    "... The truth is that the main reason all this hassle exists is because the neat partition of the ANOVA effects disappears when the data are imbalanced. In order to resolve this, we have to choose a method of partitioning the sums-of-squares. The definitions given above come directly from SAS, who's aim was not some principled statistical derivation that makes sense, rather it was to give their users what they wanted: identical ANOVA output irrespective of balance. Because the traditional ANOVA was not seen as an exercise in model building, it was not typical to remove terms that appeared redundant. In order to maintain this completeness, SAS wanted ANOVA tables that contained *all* terms, rather than certain terms disappearing under imbalance. As such, different methods for decomposing these effects were developed and a choice was provided. \n",
    "\n",
    "From a modern perspective, all this hassle is unnecessary if we engage with the process of *model building*. This is something we will discuss in much greater detail in the machine learning module next semester. However, the idea is very simple. If a term adds little predictive utility, remove it and create the simplest model you can. From this perspective, if the highest-order interaction is *small* it would be removed and then the lower-order terms become interpretable again. No need for Type II tests to make them intepretable *despite* the presence of the interaction term. However, if an interaction is *large*, it stays in the model and we only interpret the highest-order term for each factor. Under this scheme, the whole Type I/II/III debate disappears. \n",
    "\n",
    "As an example, say we have the model \n",
    "\n",
    "$$\n",
    "Y = A + B + C + AB + AC + BC + ABC.\n",
    "$$\n",
    "\n",
    "If the 3-way interaction is uninteresting, we can drop it to form\n",
    "\n",
    "$$\n",
    "Y = A + B + C + AB + AC + BC.\n",
    "$$\n",
    "\n",
    "Now, say that $AC$ and $BC$ are also uninteresting, we can settle on\n",
    "\n",
    "$$\n",
    "Y = A + B + C + AB.\n",
    "$$\n",
    "\n",
    "We would now interpret the 2-way interaction $AB$ and the main effect $C$. Because we have respected marginality here when building these models, all these terms have interpretable effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e8f2aaf",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        vs\n",
       "origin   Straight V-shaped\n",
       "  Europe        8        6\n",
       "  Japan         3        2\n",
       "  USA           3       10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data(mtcars)\n",
    "\n",
    "# Origin factor\n",
    "mtcars$origin <- c('Japan','Japan','USA','USA','USA','USA','USA','Europe','Europe',\n",
    "                   'Europe','Europe','Europe','Europe','Europe','USA','USA','USA',\n",
    "                   'Europe','Japan','Japan','Japan','USA','USA','USA','USA',\n",
    "                   'Europe','Europe','Europe','USA','Europe','Europe','Europe')\n",
    "mtcars$origin <- as.factor(mtcars$origin)\n",
    "\n",
    "# VS factor\n",
    "vs.lab <- rep(\"\",length(mtcars$vs)) \n",
    "vs.lab[mtcars$vs == 0] <- \"V-shaped\"\n",
    "vs.lab[mtcars$vs == 1] <- \"Straight\"\n",
    "mtcars$vs <- as.factor(vs.lab)\n",
    "\n",
    "with(mtcars, table(origin,vs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d63c7bb",
   "metadata": {},
   "source": [
    "`````{topic} What do you now know?\n",
    "In this section, we have explored ... After reading this section, you should have a good sense of:\n",
    "\n",
    "- ...\n",
    "- ...\n",
    "- ...\n",
    "\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f78f7a6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "[^default-foot]: Always be wary of defaults. If there is one way of getting an entire scientific field to adhere to a particular way of doing something without the need for any critical evaluation, simply make it the default in software. Defaults do not automatically hold some higher-level of credibility simply because they were the value that the developer picked. Many times these are well-considered, but this is not a *guarantee*. We can easily be led astray by default choices because we do not have to justify using them. This does not have an official name, but we could perhaps call it *the default authority effect*. It is effectively a reversal of the burden of proof: deviating from defaults requires defence, whereas using defaults is treated as neutral. Yet this presupposes that the defaults are normatively sound, which is rarely demonstrated or even documented.\n",
    "\n",
    "[^modterms-foot]: At least in terms of the sums-of-squares and mean-squares. The $F$-statistic and $p$-value depend on the error sums-of-squares, which will change depending upon the other terms in the model.\n",
    "\n",
    "[^ez-foot]: A column of effect sizes will also be given (labelled `ges`). We will discuss the nature of omnibus effect sizes later in this lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba3326",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
