{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8235c9ee",
   "metadata": {
    "tags": [
     "remove-cell"
    ],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "suppressMessages(library(car))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6b3fd6-1753-45e7-a920-fccf68cbdcac",
   "metadata": {},
   "source": [
    "# Unbalanced ANOVA Models\n",
    "The classical ANOVA was developed under the assumption that the number of data points in each cell was *identical*. This is a condition known as *balance*. This was done because, in a time before computers, the arithmetic needed to be tractable and simple to apply by hand. When Fisher first developed the ANOVA, he was working on agricultural experiments where you could easily control the number of crops planted within a certain number of fields (for example). In those situations you could design an experiment to be balanced so that the analysis would work. Unfortunately, beyond areas of science where exactact control over sampling is possible, the application of the ANOVA becomes a bit of a problem. In fields such as Psychology and Cognitve Neuroscience, a lack of balance is often the *rule* rather than the *exception*. It is easy to see why this is the case, if you have engaged in Psychological research before. Humans are notoriously unreliable and it is possible that certain groups are simply rarer to recruit than others. Removal of bad data will also upset any balance that was achieved when the data was collected. However, because the ANOVA is the *de facto* method for analysing factorial experiments, these areas of science still desire the use of the ANOVA, despite the problems this causes. \n",
    "\n",
    "```{figure} images/unbalanced-text.webp\n",
    "---\n",
    "scale: 80%\n",
    "align: right\n",
    "---\n",
    "```\n",
    "\n",
    "Such is this desire that whole textbooks have been written about unbalanced data (as can be seen on the *right*). So this is a topic that deserves some attention, even if it is often *ignored* by modern teaching in Psychology. There is something of an assumption that the issues of balance have been *solved* and thus do not need considering anymore. However, this is not really true. The \"solution\" implemented by SAS and SPSS is the Type III sums-of-squares, which researchers continue to use because it is the default[^default-foot]. However, as discussed briefly last week, this approach is highly flawed.\n",
    "\n",
    "In this part of the lesson, we will dig deeper into the Type I/II/III debate so that you understand what each type of sums-of-squares means, when they are most appropriate to use and what the various arguments are for/against them. In general, we will be recommending Type II for all use cases. However, it is important not to just take our word for it. Instead, it is important that you *understand* the differences and can make your own informed judgement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0431a6c5",
   "metadata": {},
   "source": [
    "## The Problem of Unbalance\n",
    "The arithmetic behind the traditional ANOVA relates to a simple decomposition of the sums-of-squares. Using a balanced 2-way ANOVA as an example, we simply have\n",
    "\n",
    "$$\n",
    "SS_{\\text{A}} + SS_{\\text{B}} + SS_{\\text{AB}} = SS_{\\text{Model}}.\n",
    "$$\n",
    "\n",
    "So, the total amount of variance explained by the model can be neatly decomposed into several chunks. These decompositions are said to be *orthogonal*, meaning that they are *independant*. The value of each sum-of-squares is not affected by any of the others and they represent a neat and simple partition of the amount explained by the model. Together, we then have\n",
    "\n",
    "$$\n",
    "SS_{\\text{Total}} = SS_{\\text{Model}} + SS_{\\text{Error}}.\n",
    "$$\n",
    "\n",
    "Unfortunately, when there is an *unequal* number of data points across cells, application of the standard ANOVA equations results in\n",
    "\n",
    "$$\n",
    "SS_{\\text{A}} + SS_{\\text{B}} + SS_{\\text{AB}} > SS_{\\text{Model}}.\n",
    "$$\n",
    "\n",
    "Adding these decompositions together is now *not* the same as the total amount of variance explained by the model. What happens is that the effects \"bleed\" into each other. They no longer represent an independent partition of the variance. A lack of balance kills the symmetry that allows the ANOVA to neatly decompose the variance. What this means practically is that each effect now contains some element of the other effects. Adding them together means we double-count some chunks of variance. This leads to a sum of effects that is *larger* than the amoung the model actually explains. \n",
    "\n",
    "What does this mean in terms of applying an ANOVA model to unbalanced data? It means that each sums-of-squares we calculate is influenced *by the other terms in the model*. This means we have several options when we decompose the sums-of-squares related to what else is in the model at the time. Each chunk that gets calculated will represent the variance associated with a given effect *minus* the overlap with anything else in the model. Unfortunately, wherever there is choice, there is also disagreement. For an unbalance ANOVA, this disagreement surrounds three possible ways of decomposing the sums-of-squares in an unbalanced ANOVA model. These are known as Type I, Type II and Type III, and will be the focus of this part of the lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e15f1ab",
   "metadata": {},
   "source": [
    "### Venn Diagram Intuition\n",
    "Perhaps the simplest way to gain intuition about what happens in an unbalanced ANOVA is to return to the Venn diagram visualisation we saw previously in multiple regression. Here, each circle represents the sum-of-squares associated with each main effect $\\text{A}$ and $\\text{B}$, along with their interaction $\\text{AB}$.\n",
    "\n",
    "When the ANOVA is *balanced*, the situation is as shown below\n",
    "\n",
    "```{figure} images/venn-diagrams/orthog-ANOVA.png\n",
    "---\n",
    "scale: 55%\n",
    "align: center\n",
    "---\n",
    "```\n",
    "\n",
    "Here, there is no overlap between the circles. Each effect is completely independant and it does not mater what else is in the model at the point where we calculate its sum-of-squares. We could entirely remove $\\text{B}$ and $\\text{AB}$ when calculating $SS_{\\text{A}}$ and it would not make any difference. The other model terms therefore *do not matter*, so far as the sums-of-squares are concerned.\n",
    "\n",
    "When the ANOVA is *unbalanced*, the situation is as shown below\n",
    "\n",
    "```{figure} images/venn-diagrams/unbalanced-ANOVA.png\n",
    "---\n",
    "scale: 55%\n",
    "align: center\n",
    "---\n",
    "```\n",
    "\n",
    "Here, the effects now *overlap*. This means there is some element of both $\\text{B}$ and $\\text{AB}$ inside the sum-of-squares for $\\text{A}$. This tells us why the sum of these terms is too big. If we sum the area of the $\\text{A}$ circle, $\\text{B}$ circle and $\\text{C}$ circle we will double-count the areas of overlap. This will be larger than the total area of all the circles (the $SS_{\\text{Model}}$). Furthermore, because each sum-of-squares will now depend upon the other terms in the model, we now have several options when it comes to calculating them. Using $SS_{\\text{A}}$ as an examples, we could: \n",
    "\n",
    "- Calculate $SS_{\\text{A}}$ with nothing else in the model\n",
    "- Calculate $SS_{\\text{A}}$ with $\\text{B}$ in the model, but no $\\text{AB}$. \n",
    "- Calculate $SS_{\\text{A}}$ with *both* $\\text{B}$ and $\\text{AB}$ in the model. \n",
    "\n",
    "In each case, the $SS_{\\text{A}}$ will represent only the *unique* portion of the cicle, with the overlaps removed. These options are illustrated below and correspond directly to the Type I, Type II and Type III sums-of-squares for factor A\n",
    "\n",
    "```{figure} images/venn-diagrams/SS-Types.png\n",
    "---\n",
    "scale: 55%\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2626aa56",
   "metadata": {},
   "source": [
    "## The Principle of Marginality\n",
    "In trying to determine which of the sums-of-squares to choose, we can be guided by the idea of building *meaningful* models. This is encapsulated by the *principle of marginality*, which was laid out by [Nelder (1977)](https://www.jstor.org/stable/2344517) as a response to his dissatisfaction with the way that linear models were being applied in statistics. In brief, this principle states that *if an interaction is in the model, all the constituent lower-order terms must also be in the model*.\n",
    "\n",
    "As an example, if we include $\\text{AB}$ in our model, *marginality* tells us that we must also include $\\text{A}$ and $\\text{B}$, if we want the model parameters to be interpretable. Similarly, if we include $\\text{ABC}$ we must also include $\\text{A}$, $\\text{B}$, $\\text{C}$, $\\text{AB}$, $\\text{AC}$ and $\\text{BC}$. Interpretation must then flow from the *highest-order* effects to the *lowest-order* effects. We start at the highest interactions and work our way towards the main effects. So, we must start at the *bottom* of the ANOVA table and work our way up, respecting marginality along the way. This reflects the fact that removing a lower-order term destroys the meaning of a higher-order term that contains it. For instance, removing a *main effect* ruins our ability to interpret the associated *interaction*. Remember, an interaction is defined as a *departure from additivity*. Without the additive components in the model, this deviation has no meaning.\n",
    "\n",
    "As an example, if we fit the model\n",
    "\n",
    "$$\n",
    "y_{ijk} = \\mu + \\beta_{k} + (\\alpha\\beta)_{jk} + \\epsilon_{ijk},\n",
    "$$\n",
    "\n",
    "then there is no main effect of $\\text{A}$, there is only the main effect of $\\text{B}$ and the $\\text{AB}$ interaction. However, the interaction term $(\\alpha\\beta)_{jk}$ will no longer behave as a \"deviation from additivity\". Instead, it will need to soak-up both the main effect of $\\text{A}$ and the $\\text{AB}$ interaction. So the value of this term will be a combination of the main effect and the interaction, which is uninterpretable. This is because this model *does not respect the principle of marginality* and thus the clean interpretation of each term is destroyed. Although the model above does not seem very sensible, we will see below that the Type III sums-of-squares actually make *implicit* comparisons with these forms of models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a741b7",
   "metadata": {},
   "source": [
    "## Type I Sums-of-Squares\n",
    "With some intuition about the problem of unbalanced data, and armed with the principle of marginality, we can now explore our options for deriving sums-of-squares in unbalanced models. We will start with Type I. As indicated above, the Type I sums-of-squares for factor $\\text{A}$ are calculated based on nothing else being in the model. However, this does not tell the full story. To understand the Type I effects more clearly, it is useful to introduce some new notation. In comparing the following two models\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    \\mathcal{M}_{0} &: y_{ijk} = \\mu + \\beta_{k} + \\epsilon_{ijk} \\\\\n",
    "    \\mathcal{M}_{1} &: y_{ijk} = \\mu + \\alpha_{j} + \\beta_{k} + \\epsilon_{ijk} \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "we can denote the *reduction* in residual sums-of-squares as follows\n",
    "\n",
    "$$\n",
    "R(\\alpha|\\beta).\n",
    "$$\n",
    "\n",
    "This is read as \"the reduction in residual sums-of-squares for $\\alpha$, after taking $\\beta$ into account\". So the terms on the *left* of $|$ are added and removed between the two models, whereas the terms on the *right* of $|$ remain in both models.\n",
    "\n",
    "With this in mind, the Type I sums-of-squares are a *sequential* decomposition, where terms are added *in the same order* as the model equation. Thus, for a 2-way ANOVA, the sums-of-squares for each term are as follows\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    SS_{\\text{A}}  &: R(\\alpha|\\mu)        \\\\\n",
    "    SS_{\\text{B}}  &: R(\\beta|\\mu, \\alpha) \\\\\n",
    "    SS_{\\text{AB}} &: R((\\alpha\\beta)|\\mu, \\alpha, \\beta)\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "As such, the order of the model equation matters here. Each term is added *in turn* and then compared to the previous model. So we start with only $\\mu$, we then add $\\alpha$ and see what the difference is. We then add $\\beta$ and see what the difference is, and then add the interaction and see what the difference is. Written long-hand, this would be:\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "SS_{\\text{A}}&\n",
    "\\begin{cases}\n",
    "  y_{ijk} = \\mu + \\epsilon_{ijk} \\\\\n",
    "  y_{ijk} = \\mu + \\alpha_{j} + \\epsilon_{ijk}   \n",
    "\\end{cases} \\\\\n",
    "SS_{\\text{B}}&\n",
    "\\begin{cases}\n",
    "  y_{ijk} = \\mu + \\alpha_{j} + \\epsilon_{ijk} \\\\\n",
    "  y_{ijk} = \\mu + \\alpha_{j} + \\beta_{k} + \\epsilon_{ijk}   \n",
    "\\end{cases} \\\\\n",
    "SS_{\\text{AB}}&\n",
    "\\begin{cases}\n",
    "  y_{ijk} = \\mu + \\alpha_{j} + \\beta_{k} + \\epsilon_{ijk} \\\\\n",
    "  y_{ijk} = \\mu + \\alpha_{j} + \\beta_{k} + (\\alpha\\beta)_{jk} + \\epsilon_{ijk}\n",
    "\\end{cases}\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "In terms of the Venn diagram intuition, we can see below what the standard order of terms produces when using the Type I tests.\n",
    "\n",
    "```{figure} images/venn-diagrams/SS-I.png\n",
    "---\n",
    "scale: 50%\n",
    "align: center\n",
    "---\n",
    "```\n",
    "\n",
    "Of these, the test of $\\text{B}$ and $\\text{AB}$ are useful because they take other terms into account. However, the test of $\\text{A}$ is less useful, because it does not take the effect of $\\text{B}$ into account. Importantly, however, this will change entirely if the model is specified in a *different* order. This reliance on order makes the Type I sums-of-squares dubious in their usefulness. Unfortunately, this is exactly what the `anova()` function from base `R` produces and why this method is not suitable for *unbalanced* data. Here, the adherence to marginality depends entirely upon the order in which the terms enter the model and will only produce *some* useful tests, but not necessarily all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7683d8",
   "metadata": {},
   "source": [
    "`````{admonition} Why does R default to Type I sums-of-squares?\n",
    ":class: info\n",
    "It may seem strange that the `anova()` function would choose to use the Type I sums-of-squares. However, we need to understand that `anova()` is only designed for use on *balanced* data. With this in mind, the choice of decomposition technique is entirely due to computational ease. The Type I effects are easy to calculate because we simply loop through each term, comparing the change in residual sums-of-squares to the previous model. Under balance, this is identical to the traditional ANOVA decompositon and is also identical to Type II and Type III tests. From this perspective, it is easy to see why `anova()` does things this way. However, it is important to understand that this should not be used with *unbalanced* data. At least, not without understanding what the tests actually mean.\n",
    "``````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d934b6e9",
   "metadata": {},
   "source": [
    "## Type II Sums-of-Squares\n",
    "Moving on to Type II, these sums-of-squares have a *strict* adherence to marginality. Indeed, these are the only tests that do this and is the reason why they are the recommended approach. In brief, each Type II effect is tested based on a model that contains none of its *higher-order* relatives. We will unpack what this means in more detail below.\n",
    "\n",
    "As an example, in the 2-way ANOVA we have the effects $\\text{A}$, $\\text{B}$ and $\\text{AB}$. If we wanted to test $\\text{A}$ then the Type II tests would include all the *lower-order* terms and *same-order* terms, but none of the *higher-order* terms that involve $\\text{A}$. This would mean including $\\text{B}$ but *not* $\\text{AB}$. Similarly, the Type II test of $\\text{B}$ would include $\\text{A}$, but *not* $\\text{AB}$. Finally, the test of $\\text{AB}$ would include both $\\text{A}$ *and* $\\text{B}$. In this scheme, the sums-of-squares would be\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    SS_{\\text{A}}  &: R(\\alpha|\\mu, \\beta)        \\\\\n",
    "    SS_{\\text{B}}  &: R(\\beta|\\mu, \\alpha) \\\\\n",
    "    SS_{\\text{AB}} &: R((\\alpha\\beta)|\\mu, \\alpha, \\beta)\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "Long-hand, this gives:\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "SS_{\\text{A}}&\n",
    "\\begin{cases}\n",
    "  y_{ijk} = \\mu + \\beta_{k} + \\epsilon_{ijk} \\\\\n",
    "  y_{ijk} = \\mu + \\alpha_{j} + \\beta_{k} + \\epsilon_{ijk}   \n",
    "\\end{cases} \\\\\n",
    "SS_{\\text{B}}&\n",
    "\\begin{cases}\n",
    "  y_{ijk} = \\mu + \\alpha_{j} + \\epsilon_{ijk} \\\\\n",
    "  y_{ijk} = \\mu + \\alpha_{j} + \\beta_{k} + \\epsilon_{ijk}   \n",
    "\\end{cases} \\\\\n",
    "SS_{\\text{AB}}&\n",
    "\\begin{cases}\n",
    "  y_{ijk} = \\mu + \\alpha_{j} + \\beta_{k} + \\epsilon_{ijk} \\\\\n",
    "  y_{ijk} = \\mu + \\alpha_{j} + \\beta_{k} + (\\alpha\\beta)_{jk} + \\epsilon_{ijk}\n",
    "\\end{cases}\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "So, notice that the main effects are tested *assuming their interaction is 0*. The reason is that this scheme respects marginality. This is the only way to guarantee that each test is based on an effect that is *interpretable*. If we make sure we are only ever testing the highest-order effect for the factor in question, it means the hypothesis always has a clear intepretation. For instance, the Type II test on $\\text{A}$ means that $\\text{A}$ is the highest-order term in the model (so there is no $\\text{AB}$ interaction), but will always takes all the same-order and lower-order relatives into account.\n",
    "\n",
    "However, just because an effect is *interpretable* does not necessarily mean it is *meaningful*. Whether the Type II effects have any useful meaning depends upon the other effects in the ANOVA table. We therefore have to interpret Type II effects hierarchically, from highest-order to lowest-order. Each test only makes sense if its highest-order relatives are null. So, in the 2-way example, we would only interpret the main effects of $\\text{A}$ and $\\text{B}$ if the interaction $\\text{AB}$ were null. This is because:\n",
    "\n",
    "- If the interaction was *significant* then the main effects are not meaningful and we would just interpret the interaction on its own.\n",
    "- If the interaction was *non-significant*, the only way to interpret the main effects sensibly is in a model *without* an interaction term (i.e. a purely additive model). \n",
    "\n",
    "In terms of our Venn diagram intuition, the Type II tests in the 2-way ANOVA are shown below.\n",
    "\n",
    "```{figure} images/venn-diagrams/SS-II.png\n",
    "---\n",
    "scale: 50%\n",
    "align: center\n",
    "---\n",
    "```\n",
    "\n",
    "Here we can see that $\\text{A}$ and $\\text{B}$ are tested controlling for each other, but assuming that $\\text{AB} = 0$. This makes both $\\text{A}$ and $\\text{B}$ interpretable, but only *meaningful* if the additive model is suitable. If the additive model *is* suitable, we would ignore $\\text{AB}$ anyway and so the tests on $\\text{A}$ and $\\text{B}$ make sense. If the additive model is *not* suitable, we would ignore $\\text{A}$ and $\\text{B}$ anyway and only interpret $\\text{AB}$. The Type II tests create this interpretational guarantee *without* us having to explicitly specify different models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51260ac5",
   "metadata": {},
   "source": [
    "## Type III Sums-of-Squares\n",
    "Finally, moving on to Type III, these sums-of-squares *ignore* marginality. In the presence of an interaction, the Type III tests of main effects do not assume that that interaction is 0. Instead, these tests retain the interaction in the model and make a comparison of the form\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    \\mathcal{M}_{0} &: y_{ijk} = \\mu + \\beta_{k} + (\\alpha\\beta)_{jk} + \\epsilon_{ijk} \\\\\n",
    "    \\mathcal{M}_{1} &: y_{ijk} = \\mu + \\alpha_{j} + \\beta_{k} + (\\alpha\\beta)_{jk} + \\epsilon_{ijk} \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "In other words, the Type III logic implies consideration of a model that contains an interaction, *without* one of the associated main effects. In this way, the effect of $\\text{A}$ is conceptualised as a main effect after *correcting* for both $\\text{B}$ and $\\text{AB}$. In terms of the $R$ notation, this would be\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    SS_{\\text{A}}  &: R(\\alpha|\\mu, \\beta, (\\alpha\\beta)) \\\\\n",
    "    SS_{\\text{B}}  &: R(\\beta|\\mu, \\alpha, (\\alpha\\beta)) \\\\\n",
    "    SS_{\\text{AB}} &: R((\\alpha\\beta)|\\mu, \\alpha, \\beta)\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "We can see that the test of the interaction agrees with both Type I and Type II, but the main effects do not. Now, as we argued above, a comparison such as $R(\\alpha|\\mu, \\beta, (\\alpha\\beta))$ is not particularly meaningful because the model will simply absorb the main effects into the interaction term. This makes the interaction parameters difficult to interpret, but it keeps the model fit *identical*. In fact, you cannot create the Type III tests from model comparisons alone (as we will demonstrate in `R` further below). This is already a hint that Type III tests are not asking a sensible question.\n",
    "\n",
    "Conceptually, the model comparison that Type III tests imply is very dubious, as it suggests a situation where there is 0 difference between the levels of a factor ($\\alpha_{j} = 0$), but also that this difference changes depending upon another factor ($(\\alpha\\beta)_{jk} \\neq 0$). To bring back the example from last week, if the effectiveness of a treatment depends upon diagnosis, it makes little sense to calculate the effect of treatment *correcting for* diagnosis. It is like having the following converastion: \n",
    "\n",
    "- Dr. Type III: \"So, based on your analysis, does the treament work?\"\n",
    "- You: \"Well, whether it works or not depends upon diagnosis. So, which diagnosis are we talking about?\" \n",
    "- Dr. Type III: \"...\"\n",
    "- You: \"...Are you ok, doctor?\"\n",
    "- Dr. Type III: \"Does the treatment work?\"\n",
    "- You: \"Again, it depends upon diagnosis, So, you need to tell me...\"\n",
    "- Dr. Tupe III: \"No, *ignore* diagnosis. Just tell me whether the treament works!\"\n",
    "\n",
    "In this situation, the Type II tests would say \"ok, if we set the interaction to 0, this is what we get. However, the interaction is not 0 and an additive model does not fit well here\". The Type III tests would say, \"ok, well let us *correct* the main effects for the interaction effect and interpret what is left over\". This can be severely misleading. In this situation, we could easily conclude \"the treatement does not work\". Except that the treatment *does* work, but only if you give it to the patients. \n",
    "\n",
    "In terms of the Venn diagram intuition, we can see below that the Type III main effects have the overlap with the interaction term removed. The problem is that this remaining chunk is *uninterpretable*. Yes, a number can be calculated, but conceptually it is problematic. This is most easily seen when we have a significant interaction and a non-significant main effect. The Type III claim is that these are both interpretable, but clearly this situation creates a contradiction. A treatment cannot simultaneously work and not work. We cannot conclude \"When taking diagnosis into account, the treatment is effective. However, ignoring diagnosis the treatment does nothing.\" Averaging across patients and controls is *only* meaningful under an additive model. Otherwise, we get some ficticious half-way group that is nearly a patient, but not quite, and for whom the treatment does nothing.\n",
    "\n",
    "```{figure} images/venn-diagrams/SS-III.png\n",
    "---\n",
    "scale: 50%\n",
    "align: center\n",
    "---\n",
    "```\n",
    "\n",
    "Just to hammer this point home, consider the following main effect questions that Type III effects would pose:\n",
    "\n",
    "- What is the average effect of brakes on stopping a car, adjusting for whether the car is moving?\n",
    "- What is the average effect of an umbrella on keeping you dry, adjusting for whether it is raining?\n",
    "- What is the average effect of an antibiotic for treatment, adjusting for whether there is an infection present?\n",
    "- What is the average effect of suncream on preventing sunburn, adjusting for whether you are indoors or outside?\n",
    "\n",
    "Hopefully it is clear in all these cases that the context provided by the interaction is *essential* for interpretation and that simply adjusting that context away leaves you with something entirely meaningless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0201f652",
   "metadata": {
    "tags": [
     "remove-cell"
    ],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data(mtcars)\n",
    "\n",
    "# Origin factor\n",
    "mtcars$origin <- c('Japan','Japan','USA','USA','USA','USA','USA','Europe','Europe',\n",
    "                   'Europe','Europe','Europe','Europe','Europe','USA','USA','USA',\n",
    "                   'Europe','Japan','Japan','Japan','USA','USA','USA','USA',\n",
    "                   'Europe','Europe','Europe','USA','Europe','Europe','Europe')\n",
    "mtcars$origin <- as.factor(mtcars$origin)\n",
    "\n",
    "# VS factor\n",
    "vs.lab <- rep(\"\",length(mtcars$vs)) \n",
    "vs.lab[mtcars$vs == 0] <- \"V-shaped\"\n",
    "vs.lab[mtcars$vs == 1] <- \"Straight\"\n",
    "mtcars$vs <- as.factor(vs.lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026f334",
   "metadata": {},
   "source": [
    "## Sums-of-Squares in `R`\n",
    "We will now turn to how to calculate these various types of sums-of-squares in `R`. In general, both Type I and Type III are of little practical use. As such, we would recommend just using `Anova()` for everything, which will default to Type II. However, there may be times where you wish to generate the other types (if only to placate colleagues who are more used to SPSS), so we will see how to do this below.\n",
    "\n",
    "By way of an example, we will retun the the $2 \\times 3$ ANOVA example from `mtcars`. We can examine the degree of unbalance in these data using the `tables()` function to generate a contingency table of the factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8c3627b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        vs\n",
       "origin   Straight V-shaped\n",
       "  Europe        8        6\n",
       "  Japan         3        2\n",
       "  USA           3       10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with(mtcars, table(origin,vs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be802b8e",
   "metadata": {},
   "source": [
    "So we can see that this is *severely* unbalanced data. We fit the model below and will then examine the different types of sums-of-squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07c006b7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mpg.mod <- lm(mpg ~ origin*vs, data=mtcars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b3e6c9",
   "metadata": {},
   "source": [
    "### Type I and Type II in `R`\n",
    "Type I and II sums-of-squares are simple to produce. For Type I, we can use the built-in `anova()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c2f0a48",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of Variance Table\n",
      "\n",
      "Response: mpg\n",
      "          Df Sum Sq Mean Sq F value    Pr(>F)    \n",
      "origin     2 393.88 196.938 11.4370 0.0002733 ***\n",
      "vs         1 282.26 282.261 16.3921 0.0004117 ***\n",
      "origin:vs  2   2.21   1.104  0.0641 0.9380730    \n",
      "Residuals 26 447.70  17.219                      \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "print(anova(mpg.mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5dfe56",
   "metadata": {},
   "source": [
    "These sums-of-squares can be reproduced using model comparisons, based on sequentially adding terms to each model. In the code below, we replicate the values in the `Sum Sq` column given above. This is just to illustrate the interpretation of the Type I effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0103edb",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 393.8751\n",
      "[1] 282.2613\n",
      "[1] 2.207004\n"
     ]
    }
   ],
   "source": [
    "mod.0     <- lm(mpg ~ 1,      data=mtcars)\n",
    "mod.1     <- lm(mpg ~ origin, data=mtcars)\n",
    "SS.origin <- sum(resid(mod.0)^2) - sum(resid(mod.1)^2)\n",
    "\n",
    "mod.0     <- lm(mpg ~ origin,      data=mtcars)\n",
    "mod.1     <- lm(mpg ~ origin + vs, data=mtcars)\n",
    "SS.vs     <- sum(resid(mod.0)^2) - sum(resid(mod.1)^2)\n",
    "\n",
    "mod.0     <- lm(mpg ~ origin + vs,             data=mtcars)\n",
    "mod.1     <- lm(mpg ~ origin + vs + origin:vs, data=mtcars)\n",
    "SS.inter  <- sum(resid(mod.0)^2) - sum(resid(mod.1)^2)\n",
    "\n",
    "print(SS.origin)\n",
    "print(SS.vs)\n",
    "print(SS.inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e95721",
   "metadata": {},
   "source": [
    "For Type II, we can use `Anova()` from `car` without any options, as the Type II tests are the default. We can also specify `type='II'`, if we want to be explicit about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f6c2db5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type II tests)\n",
      "\n",
      "Response: mpg\n",
      "          Sum Sq Df F value    Pr(>F)    \n",
      "origin    179.61  2  5.2153 0.0124621 *  \n",
      "vs        282.26  1 16.3921 0.0004117 ***\n",
      "origin:vs   2.21  2  0.0641 0.9380730    \n",
      "Residuals 447.70 26                      \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "library(car)\n",
    "print(Anova(mpg.mod)) # or Anova(mpg.mod, type='II')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b965bc80",
   "metadata": {},
   "source": [
    "Again, we can recreate the `Sum sq` column manually, just to make the logic clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77a04999",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 179.6085\n",
      "[1] 282.2613\n",
      "[1] 2.207004\n"
     ]
    }
   ],
   "source": [
    "mod.0     <- lm(mpg ~ vs,          data=mtcars)\n",
    "mod.1     <- lm(mpg ~ origin + vs, data=mtcars)\n",
    "SS.origin <- sum(resid(mod.0)^2) - sum(resid(mod.1)^2)\n",
    "\n",
    "mod.0     <- lm(mpg ~ origin,      data=mtcars)\n",
    "mod.1     <- lm(mpg ~ origin + vs, data=mtcars)\n",
    "SS.vs     <- sum(resid(mod.0)^2) - sum(resid(mod.1)^2)\n",
    "\n",
    "mod.0     <- lm(mpg ~ origin + vs,             data=mtcars)\n",
    "mod.1     <- lm(mpg ~ origin + vs + origin:vs, data=mtcars)\n",
    "SS.inter  <- sum(resid(mod.0)^2) - sum(resid(mod.1)^2)\n",
    "\n",
    "print(SS.origin)\n",
    "print(SS.vs)\n",
    "print(SS.inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d3c349",
   "metadata": {},
   "source": [
    "As expected, both `origin:vs` and `vs` are the same as the Type I tests, but `origin` is different. Refer back to the Venn diagrams to see why this is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf29d95",
   "metadata": {},
   "source": [
    "### Type III in `R`\n",
    "For Type III, things get trickier. We might think that we can simply specify `type='III'` in the call to `Anova()` and be done. This will produce numbers, but unfortuantely these will only correspond to the Type III effects after we have made a further change to the model.\n",
    "\n",
    "Recall from above that a Type III main effect is making the implicit comparison\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    \\mathcal{M}_{0} &: y_{ijk} = \\mu + \\beta_{k} + (\\alpha\\beta)_{jk} + \\epsilon_{ijk} \\\\\n",
    "    \\mathcal{M}_{1} &: y_{ijk} = \\mu + \\alpha_{j} + \\beta_{k} + (\\alpha\\beta)_{jk} + \\epsilon_{ijk} \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "If we try this in `R`, it will not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3324752b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] -5.684342e-14\n"
     ]
    }
   ],
   "source": [
    "mod.0     <- lm(mpg ~          vs + origin:vs, data=mtcars)\n",
    "mod.1     <- lm(mpg ~ origin + vs + origin:vs, data=mtcars)\n",
    "SS.origin <- sum(resid(mod.0)^2) - sum(resid(mod.1)^2)\n",
    "\n",
    "print(SS.origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3a2abe",
   "metadata": {},
   "source": [
    "This value is effectively `0`. Why? As stated earlier, in the model that omits `origin` the main effect will simply get absorbed into the interaction term and the model fit will be identical. As such, in order to calculate the Type III effects, the `Anova()` function has to take a different approach. We do not need to understand the details of this. The main practical point is that in order to force the Type III effects without relying on model comparisons, the effects need to be coded using a very specific dummy variable scheme. In `R`, this alternative scheme is known as *sum-to-zero* coding, as it forces the sum of each parameter associated with a given term to sum to zero (i.e. $\\sum{\\alpha_{j}} = 0$, $\\sum{\\beta_{k}} = 0$ and $\\sum{(\\alpha\\beta)_{jk}} = 0$). The impact of doing this and the reasoning behind it are beyond our current scope. The main take-away here is that, when using the `Anova()` function, the Type III tests rely on this one specific constraint in order to be correct.\n",
    "\n",
    "In order to change the contrast scheme in `R`, we have two options. The first, but *not recommended*, approach is to set the coding globally using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbcb826c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "options(contrasts=c('contr.sum','contr.poly'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e555647",
   "metadata": {},
   "source": [
    "The two options are for *unordered* and *ordered* factors. Do not worry about the second option here, it is the first option that is relevant to us. The main disadvantage of doing this is that it will change the interpretation of the parameters in all the model you use after setting this, unless you remember to set it back to normal afterwards. This means you always need to specify models in the following way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fc216bc",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: mpg\n",
      "             Sum Sq Df  F value    Pr(>F)    \n",
      "(Intercept) 10488.5  1 609.1096 < 2.2e-16 ***\n",
      "vs            251.9  1  14.6285 0.0007372 ***\n",
      "origin        166.5  2   4.8354 0.0163901 *  \n",
      "vs:origin       2.2  2   0.0641 0.9380730    \n",
      "Residuals     447.7 26                       \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "library(car)\n",
    "\n",
    "options(contrasts=c('contr.sum','contr.poly'))              # set sum-to-zero coding\n",
    "mod.sum <- lm(mpg ~ vs + origin + vs:origin, data=mtcars)   # fit model\n",
    "print(Anova(mod.sum, type='III'))                           # Type III ANOVA table\n",
    "options(contrasts=c('contr.treatment','contr.poly'))        # put the coding back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ba2ceb",
   "metadata": {},
   "source": [
    "The better approach, though the more messy in terms of syntax, is to tell `lm()` how to code each variable explicitly. This can be done using the `contrasts=` argument, which takes a list of each factor alongside how we want them coded. For this example, we will therefore use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a7be63",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: mpg\n",
      "             Sum Sq Df  F value    Pr(>F)    \n",
      "(Intercept) 10488.5  1 609.1096 < 2.2e-16 ***\n",
      "vs            251.9  1  14.6285 0.0007372 ***\n",
      "origin        166.5  2   4.8354 0.0163901 *  \n",
      "vs:origin       2.2  2   0.0641 0.9380730    \n",
      "Residuals     447.7 26                       \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "mod.sum <- lm(mpg ~ vs + origin + vs:origin, data=mtcars, \n",
    "              contrasts=list(vs=contr.sum, origin=contr.sum)) # fit model w/sum coding\n",
    "print(Anova(mod.sum, type='III'))                             # Type III ANOVA table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44acd37",
   "metadata": {},
   "source": [
    "Notice that the Type III ANOVA table also includes a test on the intercept. This is basically meaningless, but is there because the Type III logic is to test every term in the model, adjusting for everything else. So, the intercept test is comparing \n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    \\mathcal{M}_{0} &: y_{ijk} = \\alpha_{j} + \\beta_{k} + (\\alpha\\beta)_{jk} + \\epsilon_{ijk} \\\\\n",
    "    \\mathcal{M}_{1} &: y_{ijk} = \\mu + \\alpha_{j} + \\beta_{k} + (\\alpha\\beta)_{jk} + \\epsilon_{ijk} \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "Under sum-to-zero coding, this is asking whether the grand mean is 0, after adjusting for everything else in the model. This is almost never a meaningful question, yet the Type III tests ask it anyway. Notice that neither Type I or Type II do this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc83a34",
   "metadata": {},
   "source": [
    "As we can see, the Type III tests are a hassle. Now, there are deeper reasons why `car` chooses to do things this way, even though it may appear an *oversight*. However, we will not dig into this any further or dwell on it. The important point is that you need to be sure that you are using `contr.sum` with `Anova()` if you want Type III tests that are testing what you are expecting. If you want an easier method, there is the `ezANOVA()` function from the `ez` package. This will take care of all the coding mess for you behind the scenes. However, there are some disadvantages here:\n",
    "\n",
    "- `ezANOVA` aims to create output that mimics SPSS. This is not done within the linear models framework, meaning there is no access to residuals, diagnostic plots, parameter estimates or any of the useful output we want. You get an ANOVA table and nothing else[^ez-foot].\n",
    "- `ezANOVA` requires an index variable indicating which rows correspond to individual subjects, which is a little bit of a hassle.\n",
    "- By abstracting away the difficulties of Type III tests, `ezANOVA` gives the impression of simplicity and does not engage you with any of the controversy. It prints a generic warning under unbalanced data, but nothing else.\n",
    "- Fundammentally, the `ez` package aims to re-express linear models in the language of Psychology and then *hide* information from you. This is rarely a good thing.\n",
    "\n",
    "Nevertheless, if you want the simplest possible method of generating a Type III table that you *know* is correct, you can do the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a7d7233",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“Data is unbalanced (unequal N per group). Make sure you specified a well-considered value for the type argument to ezANOVA().”\n",
      "Coefficient covariances computed by hccm()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Effect DFn DFd           F            p p<.05         ges\n",
      "2        vs   1  26 14.62853431 0.0007372137     * 0.360055674\n",
      "3    origin   2  26  4.83541867 0.0163900610     * 0.271113270\n",
      "4 vs:origin   2  26  0.06408491 0.9380730371       0.004905426\n"
     ]
    }
   ],
   "source": [
    "library(ez)\n",
    "\n",
    "mtcars$idx <- as.factor(seq(from=1, to=dim(mtcars)[1])) # ezANOVA needs subject IDs\n",
    "ezAOV      <- ezANOVA(data=mtcars,          # data\n",
    "                      dv=mpg,               # outcome\n",
    "                      between=.(vs,origin), # between-subject factors  \n",
    "                      wid=idx,              # subject IDs\n",
    "                      type=3)               # sums-of-squares\n",
    "\n",
    "print(ezAOV$ANOVA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673b548d",
   "metadata": {},
   "source": [
    "## Reassessing the Sums-of-squares Circus\n",
    "By this point, you probably have the impression that all this sums-of-squares business is a bit of a mess. You would not be wrong. However, we can resolve it quite easily by saying\n",
    "\n",
    "- Always use `Anova()` with `type='II'`\n",
    "- Use the principle of marginality to guide interpretation\n",
    "\n",
    "This gets around most of the mess and also guarantees that the hypotheses are always interpretable and are based on actual model comparisons that you can recreate for yourself. \n",
    "\n",
    "The bigger picture here is one of sensible model building. The ANOVA exists primarily as a way of performing hypothesis tests on models that contain *all* the factorial terms. The Type II tests then have to derive hypotheses that ask questions based on what the results would be if certain terms were 0, even in models where they may not be 0. This is quite complex to do. In general, we are much better served by building models that *remove* null terms. If we do this and then use marginality, we can side-step a lot of this hassle. \n",
    "\n",
    "As an example, say we have the model \n",
    "\n",
    "$$\n",
    "Y = A + B + C + AB + AC + BC + ABC.\n",
    "$$\n",
    "\n",
    "If the 3-way interaction is uninteresting, we can drop it to form\n",
    "\n",
    "$$\n",
    "Y = A + B + C + AB + AC + BC.\n",
    "$$\n",
    "\n",
    "Now, say that $AB$ and $AC$ are also uninteresting, we can settle on\n",
    "\n",
    "$$\n",
    "Y = A + B + C + BC.\n",
    "$$\n",
    "\n",
    "We would now interpret the 2-way interaction $BC$ and the main effect $A$. Because we have respected marginality here when building these models, both these terms have interpretable effects and the Type II and Type III distinction disappears. Indeed, we can easily produce these tests using model comparisons and they will be easily interpretable, as each effect is the highest-order term for each factor in the model. For instance, using a simulated unbalanced dataset for demonstration, we have: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93e84e6c",
   "metadata": {
    "tags": [
     "remove-cell"
    ],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "\n",
    "## factors\n",
    "A <- factor(c(\"A1\", \"A2\"))\n",
    "B <- factor(c(\"B1\", \"B2\", \"B3\"))\n",
    "C <- factor(c(\"C1\", \"C2\"))\n",
    "\n",
    "## unbalanced cell sizes\n",
    "cell_n <- expand.grid(A = A, B = B, C = C)\n",
    "cell_n$n <- c(\n",
    "  12,  3,   # A1 B1 C1/C2\n",
    "   5, 15,   # A1 B2 C1/C2\n",
    "  20,  4,   # A1 B3 C1/C2\n",
    "   2, 18,   # A2 B1 C1/C2\n",
    "  10,  3,   # A2 B2 C1/C2\n",
    "   4, 25    # A2 B3 C1/C2\n",
    ")\n",
    "\n",
    "## true effects\n",
    "A_eff  <- c(A1 = 0, A2 = 2)\n",
    "B_eff  <- c(B1 = 0, B2 = 1, B3 = -1)\n",
    "C_eff  <- c(C1 = 0, C2 = 1)\n",
    "\n",
    "## BC interaction only\n",
    "BC_int <- matrix(\n",
    "  c( 0,  0,\n",
    "     0,  2,\n",
    "     0, -2),\n",
    "  nrow = 3, byrow = TRUE,\n",
    "  dimnames = list(B, C)\n",
    ")\n",
    "\n",
    "## generate data\n",
    "dat <- do.call(rbind, lapply(seq_len(nrow(cell_n)), function(i) {\n",
    "  with(cell_n[i, ], {\n",
    "    mu <- 10 +\n",
    "      A_eff[A] +\n",
    "      B_eff[B] +\n",
    "      C_eff[C] +\n",
    "      BC_int[B, C]\n",
    "    data.frame(\n",
    "      y = rnorm(n, mu, sd = 2),\n",
    "      A = A, B = B, C = C\n",
    "    )\n",
    "  })\n",
    "}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fea5d7e7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of Variance Table\n",
      "\n",
      "Model 1: y ~ B + C + B:C\n",
      "Model 2: y ~ A + B + C + B:C\n",
      "  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n",
      "1    115 427.91                                  \n",
      "2    114 368.48  1     59.43 18.386 3.793e-05 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "Analysis of Variance Table\n",
      "\n",
      "Model 1: y ~ A + B + C\n",
      "Model 2: y ~ A + B + C + B:C\n",
      "  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n",
      "1    116 461.62                                  \n",
      "2    114 368.48  2    93.139 14.408 2.639e-06 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "# Effect of A\n",
    "null.mod <- lm(y ~     B + C + B:C, data=dat)\n",
    "full.mod <- lm(y ~ A + B + C + B:C, data=dat)\n",
    "print(anova(null.mod,full.mod))\n",
    "\n",
    "# Effect of BC\n",
    "null.mod <- lm(y ~ A + B + C,       data=dat)\n",
    "full.mod <- lm(y ~ A + B + C + B:C, data=dat)\n",
    "print(anova(null.mod,full.mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b9d139",
   "metadata": {},
   "source": [
    "Note that this is *not* the approach you will find in the mainstream Psychology literature. However, it is the most coherent and cohesive method of getting around all the sums-of-squares hassle that agrees directly with the ideas of model comparisons *and* respects marginality. Each effect is therefore *interpretable* and comes from the most parsimonious and best-fitting model for our data. We will discuss much more about model comparisons and model building in the Machine Learning module, so do not worry about this too much for now. Just know that there *is* an alternative to the ANOVA table in these types of models that retains the spirit of model comparisons, but without all the hassle of answering ill-defined questions under unbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d63c7bb",
   "metadata": {},
   "source": [
    "`````{topic} What do you now know?\n",
    "In this section, we have explored unbalanced ANOVA models and the choice of sums-of-squares. After reading this section, you should have a good sense of:\n",
    "\n",
    "- What unbalance means and why it is a problem.\n",
    "- The idea that when the data are unbalanced, the sums-of-squares depend upon what other terms are in the model.\n",
    "- The principle of marginality as a guideline for always considering models with interpretable effects.\n",
    "- What the Type I sums-of-squares are and why they are often less interesting.\n",
    "- What the Type II sums-of-squares are and why they are recommended as a default.\n",
    "- What the Type III sums-of-squares are and why they are *not* recommended, despite being the default in other software.\n",
    "- How to correctly generate Type I/II/III ANOVA tables in `R`  \n",
    "\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f78f7a6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "[^default-foot]: Always be wary of defaults. If there is one way of getting an entire scientific field to adhere to a particular way of doing something without the need for any critical evaluation, simply make it the default in software. Defaults do not automatically hold some higher-level of credibility simply because they were the value that the developer picked. Many times these are well-considered, but this is not a *guarantee*.\n",
    "\n",
    "[^modterms-foot]: At least in terms of the sums-of-squares and mean-squares. The $F$-statistic and $p$-value depend on the error sums-of-squares, which will change depending upon the other terms in the model.\n",
    "\n",
    "[^ez-foot]: A column of effect sizes will also be given (labelled `ges`). We will discuss the nature of omnibus effect sizes later in this lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba3326",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
