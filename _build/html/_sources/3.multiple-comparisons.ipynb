{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f8f4ad",
   "metadata": {
    "tags": [
     "remove-cell"
    ],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "suppressMessages(library(car))\n",
    "suppressMessages(library(effects))\n",
    "suppressMessages(library(emmeans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c9bb06",
   "metadata": {},
   "source": [
    "# Effects Sizes and Multiple Comparisons Correction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513662f8",
   "metadata": {},
   "source": [
    "\n",
    "As the final section in this part of the lesson, we need to take a moment to consider the topic of follow-up tests and multiple comparisons. In the previous lesson, we justified the use of omnibus tests as a guard against the multiple testing problem. Even though this guard exists at a higher-level, when we use the omnibus tests to guide the follow-up tests we still run the risk of false positives. As such, it is customary to apply some degree of correction to the follow-up tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f38cafa",
   "metadata": {},
   "source": [
    "### Corrections in `R`\n",
    "\n",
    "General access to $p$-values corrections is available in base `R` using the `p.adjust()` function. We simply supply a list of $p$-values and the name of the method we want to use and `R` will return the adjusted values. For instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57582acf",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.008 1.000 0.200 0.492\n"
     ]
    }
   ],
   "source": [
    "p.raw <- c(0.002, 0.765, 0.05, 0.123)\n",
    "p.adj <- p.adjust(p=p.raw, method=\"bonferroni\")\n",
    "\n",
    "print(p.adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a46325",
   "metadata": {},
   "source": [
    "In this example, the basic Bonferroni method is used where each $p$-value is multiplied by the number of $p$-values. We can see this for ourseleves by calculating this correction manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "033fb67d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.008 1.000 0.200 0.492\n"
     ]
    }
   ],
   "source": [
    "# bonferroni correction\n",
    "n.p   <- length(p.raw)\n",
    "p.adj <- p.raw * n.p \n",
    "\n",
    "# make sure all p <= 1\n",
    "for (i in 1:n.p){\n",
    "    if (p.adj[i] > 1){\n",
    "        p.adj[i] <- 1\n",
    "    }\n",
    "}\n",
    "\n",
    "print(p.adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acd07e4",
   "metadata": {},
   "source": [
    "In terms of other adjustment methods, `R` has 6 built-in possibilities that can be listed by calling `p.adjust.methods`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e76414fa",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"holm\"       \"hochberg\"   \"hommel\"     \"bonferroni\" \"BH\"        \n",
      "[6] \"BY\"         \"fdr\"        \"none\"      \n"
     ]
    }
   ],
   "source": [
    "print(p.adjust.methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f12bb",
   "metadata": {},
   "source": [
    "noting that `fdr` is an alias for `BH`, and `none` is just a pass-through option that does nothing. It is somewhat beyond this lesson to go into the details of all of these. So, a very general heuristic is to use the `holm` method as the most general-purpose approach. This is more powerful than `bonferroni`[^bonf-foot], but has no additional assumptions. If the $p$-values are *correlated* (e.g. from repeated measurements), then `hochberg` is a better choice because it relaxes the assumption of independance yet retains good power.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cff769a",
   "metadata": {},
   "source": [
    "### Corrections and Families of Tests in `emmeans`\n",
    "In terms of using these corrections within `emmeans`, it is a simple as using the `adjust` argument to name the correction that we want applied. As an example, using the `holm` method with the follow-up tests of the `vs:origin` interaction gives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcc98395",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin = Europe:\n",
      " contrast              estimate   SE df t.ratio p.value\n",
      " Straight - (V-shaped)     6.20 2.24 26   2.765  0.0103\n",
      "\n",
      "origin = Japan:\n",
      " contrast              estimate   SE df t.ratio p.value\n",
      " Straight - (V-shaped)    -7.40 3.79 26  -1.954  0.0616\n",
      "\n",
      "origin = USA:\n",
      " contrast              estimate   SE df t.ratio p.value\n",
      " Straight - (V-shaped)     6.02 2.73 26   2.203  0.0367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emm <- emmeans(mod, pairwise ~ vs|origin, adjust=\"holm\")\n",
    "print(emm$contrasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484f889d",
   "metadata": {},
   "source": [
    "Now, you would be forgiven for thinking that nothing has changed here. And, in fact, you would be right. In this instance, `emmeans` has not applied any correction, despite our request. So what is going on?\n",
    "\n",
    "The answer is that concept of multiple comparisons is not always as straightforward as it might seem. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b96083",
   "metadata": {},
   "source": [
    "\n",
    "... Each level of the second factor is taken to define a family of tests, independent from other levels. We can see this if we swap the tests defined earlier to look at the effects of `origin` at each level of `vs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf5db2de",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs = Straight:\n",
      " contrast       estimate   SE df t.ratio p.value\n",
      " Europe - Japan    -4.14 2.81 26  -1.473  0.3056\n",
      " Europe - USA       3.70 2.81 26   1.316  0.3056\n",
      " Japan - USA        7.83 3.39 26   2.312  0.0869\n",
      "\n",
      "vs = V-shaped:\n",
      " contrast       estimate   SE df t.ratio p.value\n",
      " Europe - Japan   -17.73 3.39 26  -5.234  <.0001\n",
      " Europe - USA       3.52 2.14 26   1.641  0.1128\n",
      " Japan - USA       21.25 3.21 26   6.611  <.0001\n",
      "\n",
      "P value adjustment: holm method for 3 tests \n"
     ]
    }
   ],
   "source": [
    "emm <- emmeans(mod, pairwise ~ origin|vs, adjust=\"holm\")\n",
    "print(emm$contrasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4a5161",
   "metadata": {},
   "source": [
    "So, `emmeans` takes this as two families, each containing 3 tests. Corrections to the $p$-values are then applied *within* families."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9dbc8c",
   "metadata": {},
   "source": [
    "### Planned Comparisons vs Post-hoc Tests\n",
    "... Beware of this reasoning. Although planned tests are more *credible* in the sense that you are not $p$-hacking, this does not change anything about the error rate. The error does not magically know what your intentions were and then change itself. The error rate is a fact of multiple testing that does not change with intent. As such, even if you have pre-specified tests, you still need to control for multiple comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e86174",
   "metadata": {},
   "source": [
    "[^fake-foot]: Remember, these data are *entirely* fabricated. There is nothing magical about Japanese cars that makes V-shaped engines super efficient in terms of MPG.\n",
    "\n",
    "[^modmat-foot]: You do not need to construct these weights manually, as shown in the code. Instead, you can get the coding for the *whole* model by using the `model.matrix()` function and passing in the model object. This will show you the *exact* coding for every data point in the model.\n",
    "\n",
    "[^cohen-foot]: Cohen's aim was to get practitioners away from $p$-values and the dichotomisation of evidence. So, instead, he decided to *trichotomise* his measure of effect size into *Small = 0.2*, *Medium = 0.5* and *Large = 0.8*. In Cohen's defence, this was likely a compromise position to try and get his effect size adopted by researchers who do not like subtlety and nuance in their results and would rather just have rules to follow. This is something you will come up against time and time again in the wider world of research.\n",
    "\n",
    "[^neg-foot]: The fact that this is `-1` rather than `1` makes no differences. It just reverses the direction of the comparison.\n",
    "\n",
    "[^followup-foot]: This is the approach often advocated in Psychology to follow-up an ANOVA, but it is far from the most appropriate.\n",
    "\n",
    "[^bonf-foot]: Bonferroni is a very common correction where each $p$-value is multiplied by the number of tests.\n",
    "\n",
    "[^interact-foot]: Alternatively, we can think of this as indicating that the differences in MPG betwee `Japan`, `USA` and `Europe` depends upon whether the engine is `Straight` or `V-Shaped`. Although interactions can be interpreted different ways around, for most problems there is usually one way of conceptualising the interaction that is more intuitive or useful than the other.\n",
    "\n",
    "[^regmc-foot]: Though we should be aware that the regression tests are not corrected for multiple comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dde02f2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
