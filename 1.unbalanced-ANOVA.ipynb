{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe8c6f1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: carData\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(car)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6b3fd6-1753-45e7-a920-fccf68cbdcac",
   "metadata": {},
   "source": [
    "# Unbalanced ANOVA Models\n",
    "\n",
    "```{figure} images/unbalanced-text.webp\n",
    "---\n",
    "scale: 80%\n",
    "align: right\n",
    "---\n",
    "```\n",
    "\n",
    "... Indeed, whole textbooks were written about unbalanced data (as can be seen on the *right*). So this is a topic that deserves some attention, even if it is largely *ignored* by modern teaching in Psychology. There is something of an assumption that the issues of balance have been *solved* and thus do not need considering anymore. However, this is not really true. The \"solution\" implemented by SAS and SPSS is the Type III sums-of-squares, which researchers continue to use because it is the default[^default-foot]. However, as discussed briefly last week, this approach is highly flawed.\n",
    "\n",
    "In this part of the lesson, we will dig deeper into the Type I/II/III debate so that you understand what each type of sums-of-squares means, when they are most appropriate to use and what the various arguments are for/against them. In general, we will be recommending Type II for 95% of all use-cases. However, it is important not to just take our word for it. Instead, it is important that you *understand* the difference and can make your own informed judgement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0431a6c5",
   "metadata": {},
   "source": [
    "## The Problem of Imbalance\n",
    "... Perhaps the most important thing to recognise here is that imbalance is only a problem when we insist on trying to interpret effects that *do not make sense* in the context of the model. For instance, trying to interpret a main effect in the presence of an interaction. If an interaction effect is *large* then the main effects make no sense however, when the interaction effect is *small*, it adds little to the predictive accuracy of the model and should not be there. \n",
    "\n",
    "The key point here is that all this hassle goes away if we just engage with the idea of *model building* and only interpret tests once we have a suitable model in place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2626aa56",
   "metadata": {},
   "source": [
    "## The Principle of Marginality\n",
    "One of the key ways of resolving "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a741b7",
   "metadata": {},
   "source": [
    "## Type I Sums-of-squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d934b6e9",
   "metadata": {},
   "source": [
    "## Type II Sums-of-squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51260ac5",
   "metadata": {},
   "source": [
    "## Type III Sums-of-squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06cddd8c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data(mtcars)\n",
    "\n",
    "# Origin factor\n",
    "mtcars$origin <- c('Japan','Japan','USA','USA','USA','USA','USA','Europe','Europe',\n",
    "                   'Europe','Europe','Europe','Europe','Europe','USA','USA','USA',\n",
    "                   'Europe','Japan','Japan','Japan','USA','USA','USA','USA',\n",
    "                   'Europe','Europe','Europe','USA','Europe','Europe','Europe')\n",
    "mtcars$origin <- as.factor(mtcars$origin)\n",
    "\n",
    "# VS factor\n",
    "vs.lab <- rep(\"\",length(mtcars$vs)) \n",
    "vs.lab[mtcars$vs == 0] <- \"V-shaped\"\n",
    "vs.lab[mtcars$vs == 1] <- \"Straight\"\n",
    "mtcars$vs <- as.factor(vs.lab)\n",
    "\n",
    "# Create fake interaction\n",
    "mpg.fake          <- mtcars$mpg                  # copy mpg\n",
    "mpg.idx           <- mtcars$origin == \"Japan\" &\n",
    "                     mtcars$vs     == \"V-shaped\" # index of Japan-VShaped cell\n",
    "mpg.fake[mpg.idx] <- mpg.fake[mpg.idx] + 15      # add constant to all data from that cell\n",
    "mtcars$mpg.fake   <- mpg.fake   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a89bc9ec",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single term deletions\n",
      "\n",
      "Model:\n",
      "mpg.fake ~ vs + origin + vs:origin\n",
      "       Df Sum of Sq    RSS     AIC F value  Pr(>F)  \n",
      "<none>              447.70  96.429                  \n",
      "vs      1    131.62 579.32 102.676  7.6436 0.01034 *\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A anova: 5 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Sum Sq</th><th scope=col>Df</th><th scope=col>F value</th><th scope=col>Pr(&gt;F)</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>4787.31125</td><td> 1</td><td>278.018874</td><td>2.114455e-15</td></tr>\n",
       "\t<tr><th scope=row>vs</th><td> 131.61720</td><td> 1</td><td>  7.643553</td><td>1.033623e-02</td></tr>\n",
       "\t<tr><th scope=row>origin</th><td>  92.20887</td><td> 2</td><td>  2.677474</td><td>8.763434e-02</td></tr>\n",
       "\t<tr><th scope=row>vs:origin</th><td> 181.54541</td><td> 2</td><td>  5.271545</td><td>1.197251e-02</td></tr>\n",
       "\t<tr><th scope=row>Residuals</th><td> 447.70375</td><td>26</td><td>        NA</td><td>          NA</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A anova: 5 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & Sum Sq & Df & F value & Pr(>F)\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t(Intercept) & 4787.31125 &  1 & 278.018874 & 2.114455e-15\\\\\n",
       "\tvs &  131.61720 &  1 &   7.643553 & 1.033623e-02\\\\\n",
       "\torigin &   92.20887 &  2 &   2.677474 & 8.763434e-02\\\\\n",
       "\tvs:origin &  181.54541 &  2 &   5.271545 & 1.197251e-02\\\\\n",
       "\tResiduals &  447.70375 & 26 &         NA &           NA\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A anova: 5 × 4\n",
       "\n",
       "| <!--/--> | Sum Sq &lt;dbl&gt; | Df &lt;dbl&gt; | F value &lt;dbl&gt; | Pr(&gt;F) &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| (Intercept) | 4787.31125 |  1 | 278.018874 | 2.114455e-15 |\n",
       "| vs |  131.61720 |  1 |   7.643553 | 1.033623e-02 |\n",
       "| origin |   92.20887 |  2 |   2.677474 | 8.763434e-02 |\n",
       "| vs:origin |  181.54541 |  2 |   5.271545 | 1.197251e-02 |\n",
       "| Residuals |  447.70375 | 26 |         NA |           NA |\n",
       "\n"
      ],
      "text/plain": [
       "            Sum Sq     Df F value    Pr(>F)      \n",
       "(Intercept) 4787.31125  1 278.018874 2.114455e-15\n",
       "vs           131.61720  1   7.643553 1.033623e-02\n",
       "origin        92.20887  2   2.677474 8.763434e-02\n",
       "vs:origin    181.54541  2   5.271545 1.197251e-02\n",
       "Residuals    447.70375 26         NA           NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod.full <- lm(mpg.fake ~ vs + origin + vs:origin, data=mtcars)\n",
    "\n",
    "print(drop1(mod.full, scope=\"vs\", test=\"F\"))\n",
    "Anova(mod.full, type=\"III\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc4df71",
   "metadata": {},
   "source": [
    "So this had not worked. Why? The reason is due to the form of dummy coding used by `R`. Put simply, the missing term `vs` is absorbed into the `vs:origin` term, making the two models *identical*. In fact, the only way to get this comparison to produce a result for us is to *change* the dummy coding. The fact that we need to adjust an arbitrary element of the model to get the numbers we want should be a clue that this is *not* a sensible comparison to make. Nevertheless, if we change the coding to a form where each term represents an independant element of the variance decomposition, we can get a result here. This form of coding is known as *sum-to-zero* coding, or *sum* coding for short. We do not need to understand this in any great detail, but we do need to highlight that the result depends on the coding. This means that Type III tests only work *under certain ANOVA constraints*. Given that the constraint is not a core component of the model (as the model will work identically under any arbitrary constrain), this is another clue that this method makes little sense. \n",
    "\n",
    "In the example below, we set the coding used for each factor in the call to `lm()`. This *can* be set globally, but then it becomes easy to forget to switch it back again and we may get confused when trying to interpret the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4369502",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: mpg.fake\n",
      "             Sum Sq Df  F value    Pr(>F)    \n",
      "(Intercept) 13094.1  1 760.4268 < 2.2e-16 ***\n",
      "vs             14.9  1   0.8631   0.36142    \n",
      "origin        680.8  2  19.7672 6.033e-06 ***\n",
      "vs:origin     181.5  2   5.2715   0.01197 *  \n",
      "Residuals     447.7 26                       \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "Single term deletions\n",
      "\n",
      "Model:\n",
      "mpg.fake ~ vs + origin + vs:origin\n",
      "       Df Sum of Sq    RSS    AIC F value Pr(>F)\n",
      "<none>              447.70 96.429               \n",
      "vs      1    14.862 462.57 95.474  0.8631 0.3614\n"
     ]
    }
   ],
   "source": [
    "mod.sum <- lm(mpg.fake ~ vs + origin + vs:origin, data=mtcars, contrasts=list(vs=contr.sum, origin=contr.sum))\n",
    "\n",
    "print(Anova(mod.sum, type=\"III\"))\n",
    "print(drop1(mod.sum, scope = \"vs\", test = \"F\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673b548d",
   "metadata": {},
   "source": [
    "## Resolving the Sums-of-squares Circus\n",
    "... The truth is that the main reason all this hassle exists is because the neat partition of the ANOVA effects disappears when the data are imbalanced. In order to resolve this, we have to choose a method of partitioning the sums-of-squares. The definitions given above come directly from SAS, who's aim was not some principled statistical derivation that makes sense, rather it was to give their users what they wanted: identical ANOVA output irrespective of balance. Because the traditional ANOVA was not seen as an exercise in model building, it was not typical to remove terms that appeared redundant. In order to maintain this completeness, SAS wanted ANOVA tables that contained *all* terms, rather than certain terms disappearing under imbalance. As such, different methods for decomposing these effects were developed and a choice was provided. \n",
    "\n",
    "From a modern perspective, all this hassle is unnecessary if we engage with the process of *model building*. This is something we will discuss in much greater detail in the machine learning module next semester. However, the idea is very simple. If a term adds little predictive utility, remove it and create the simplest model you can. From this perspective, if the highest-order interaction is *small* it would be removed and then the lower-order terms become interpretable again. No need for Type II tests to make them intepretable *despite* the presence of the interaction term. However, if an interaction is *large*, it stays in the model and we only interpret the highest-order term for each factor. Under this scheme, the whole Type I/II/III debate disappears. \n",
    "\n",
    "As an example, say we have the model \n",
    "\n",
    "$$\n",
    "Y = A + B + C + AB + AC + BC + ABC.\n",
    "$$\n",
    "\n",
    "If the 3-way interaction is uninteresting, we can drop it to form\n",
    "\n",
    "$$\n",
    "Y = A + B + C + AB + AC + BC.\n",
    "$$\n",
    "\n",
    "Now, say that $AC$ and $BC$ are also uninteresting, we can settle on\n",
    "\n",
    "$$\n",
    "Y = A + B + C + AB.\n",
    "$$\n",
    "\n",
    "We would now interpret the 2-way interaction $AB$ and the main effect $C$. Because we have respected marginality here when building these models, all these terms have interpretable effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e8f2aaf",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(\"datarium\"): there is no package called ‘datarium’\n",
     "output_type": "error",
     "traceback": [
      "Error in library(\"datarium\"): there is no package called ‘datarium’\nTraceback:\n",
      "1. stop(packageNotFoundError(package, lib.loc, sys.call()))"
     ]
    }
   ],
   "source": [
    "library('datarium')\n",
    "library('car')\n",
    "data(headache)\n",
    "mod <- lm(pain_score ~ gender*risk*treatment, data=headache)\n",
    "print(Anova(mod))\n",
    "\n",
    "mod <- lm(pain_score ~ gender + risk + treatment + risk:treatment, data=headache)\n",
    "\n",
    "mod.sum <- lm(pain_score ~ gender + risk + treatment + risk:treatment, data=headache, contrasts=list(gender=contr.sum,risk=contr.sum,treatment=contr.sum))\n",
    "\n",
    "print(anova(mod))\n",
    "print(Anova(mod))\n",
    "print(Anova(mod.sum, type=\"III\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d63c7bb",
   "metadata": {},
   "source": [
    "`````{topic} What do you now know?\n",
    "In this section, we have explored ... After reading this section, you should have a good sense of:\n",
    "\n",
    "- ...\n",
    "- ...\n",
    "- ...\n",
    "\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f78f7a6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "[^default-foot]: Always be wary of defaults. If there is one way of getting an entire scientific field to adhere to a particular way of doing something without the need for any critical evaluation, simply make it the default in software. Defaults do not automatically hold some higher-level of credibility simply because they were the value that the developer picked. Many times these are well-considered, but this is not a *guarantee*. We can easily be led astray by default choices because we do not have to justify using them. This does not have an official name, but we could perhaps call it *the default authority effect*. It is effectively a reversal of the burden of proof: deviating from defaults requires defence, whereas using defaults is treated as neutral. Yet this presupposes that the defaults are normatively sound, which is rarely demonstrated or even documented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba3326",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
